{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code Utama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "class eksperimen(object):\n",
    "    def __init__(self, dataset=None, classifier=None, X=None, y=None, dataset_split=None, feature_names=None, target_names=None):\n",
    "        self.dataset = dataset\n",
    "        self.classifier = classifier\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.dataset_split = dataset_split\n",
    "        self.feature_names = feature_names\n",
    "        self.target_names = target_names\n",
    "\n",
    "    def get_std_dataset(self):\n",
    "        self.dataset = load_iris()\n",
    "        self.X = self.dataset['data']\n",
    "        self.y = self.dataset['target']\n",
    "\n",
    "    def printmatrix_accuracy_percentage(self):\n",
    "        predict = self.classifier.predict(self.dataset_split['X_test'])\n",
    "    \n",
    "        # accuracy\n",
    "        print(accuracy_score(self.dataset_split['y_test'],predict))\n",
    "\n",
    "        # metrics confusion\n",
    "        print(confusion_matrix(self.dataset_split['y_test'],predict))\n",
    "    \n",
    "    def build_clf_percentage(self, clf_name):\n",
    "        if (clf_name == 'dtl'):\n",
    "            self.classifier = DecisionTreeClassifier(max_leaf_nodes=20, random_state=0)\n",
    "        elif (clf_name == 'ann'):\n",
    "            self.classifier = MLPClassifier(solver='lbfgs', alpha=1e-5, \n",
    "                                            hidden_layer_sizes=(10, 2), random_state=1)\n",
    "        # training dengan 90% data   \n",
    "        self.classifier.fit(self.dataset_split['X_train'],self.dataset_split['y_train'])\n",
    "\n",
    "    def build_clf_full(self,clf_name):\n",
    "        if (clf_name == 'dtl'):\n",
    "            self.classifier = DecisionTreeClassifier(max_leaf_nodes=20, random_state=0)\n",
    "        elif (clf_name == 'ann'):\n",
    "            self.classifier = MLPClassifier(solver='lbfgs', alpha=1e-5, \n",
    "                                            hidden_layer_sizes=(10, 5), random_state=1)\n",
    "        # training dengan full data   \n",
    "        self.classifier.fit(self.X,self.y)\n",
    "        \n",
    "    def saveModel(self,namaFile):\n",
    "        joblib.dump(self.classifier,namaFile)\n",
    "    \n",
    "    def loadModel(self,namaFile):\n",
    "        self.classifier= joblib.load(namaFile)\n",
    "    \n",
    "    def split_dataset(self):\n",
    "        # X adalah data setiap fitur, y adalah target \n",
    "        # split menjadi 90% training 10% testing\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size = 0.1 ,train_size = 0.9)\n",
    "        self.dataset_split = {\n",
    "            'X_train': X_train,\n",
    "            'X_test': X_test,\n",
    "            'y_train': y_train,\n",
    "            'y_test': y_test\n",
    "        }\n",
    "\n",
    "    def get_dataset(self, filename, class_index):\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        raw_data = pd.read_csv(filename, header=None)\n",
    "        array_nama_atribut = raw_data.columns\n",
    "        \n",
    "        feature_names = []\n",
    "        index = 0\n",
    "        for name in array_nama_atribut:\n",
    "            if (index != class_index):\n",
    "                feature_names.append(name)\n",
    "            index += 1\n",
    "        self.feature_names = feature_names\n",
    "   \n",
    "        le.fit(raw_data[raw_data.columns[class_index]])\n",
    "        self.target_names = le.classes_\n",
    "        \n",
    "        for key in array_nama_atribut:\n",
    "            list_value = raw_data[key]\n",
    "            value = []\n",
    "            for i in list_value:\n",
    "                value.append(i)\n",
    "            le.fit(value)\n",
    "            # save le\n",
    "            val = le.transform(value)\n",
    "            raw_data[key] = val\n",
    "        \n",
    "        self.dataset = raw_data\n",
    "        \n",
    "        y = [] # target\n",
    "        for target in raw_data[raw_data.columns[class_index]]: # play is the name of the class index\n",
    "            y.append(target)\n",
    "        self.y = y\n",
    "        X = [] # domain\n",
    "        i = 0\n",
    "        jumlah_data = len(raw_data)\n",
    "        while (i<jumlah_data):\n",
    "            elem_x = []\n",
    "            test = 0\n",
    "            for elem in raw_data.columns:\n",
    "                if (test != class_index):\n",
    "                    elem_x.append(raw_data.loc[i, elem])\n",
    "                test += 1\n",
    "            X.append(elem_x)\n",
    "            i += 1\n",
    "        self.X = X\n",
    "    \n",
    "    def get10FoldCrossValidation_ann(self):\n",
    "        # isi hidden layer sesuai dengan data\n",
    "        self.classifier = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(10, 1), random_state=1)\n",
    "        score = cross_val_score(self.classifier, self.X, self.y, cv=10)\n",
    "        print(score.mean())\n",
    "        \n",
    "    def get10FoldCrossValidation_dtl(self):\n",
    "        self.classifier = DecisionTreeClassifier(max_leaf_nodes=20, random_state=0)\n",
    "        score = cross_val_score(self.classifier, self.X, self.y, cv=10)\n",
    "        print(score.mean())\n",
    "    \n",
    "exp = eksperimen()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAPORAN UTAMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Analisis Data dan Penanganan\n",
    "\n",
    "### Analisis Data\n",
    "Dalam eksperimen ini, dataset yang digunakan bernama CensusIncome. CensusIncome merupakan data dengan jumlah fitur sebanyak 14. Kelas yang merupakan target dari dataset ini adalah \"<50K\" dan \">=50K\". Untuk mengukur kinerja dari eksperimen ini, kami melihat dari akurasi yang didapatkan pada setiap *testing* yang dilakukan.\n",
    "\n",
    "### Penanganan Khusus\n",
    "Penanganan yang kami lakukan pada eksperimen ini, yaitu:\n",
    "1. Mengubah nilai-nilai nominal pada dataset agar dapat diproses oleh *classifier* DTL dan ANN\n",
    "2. *Missing Attributes* dianggap menjadi sebuah nominal yang sama\n",
    "3. Untuk setiap nilai nominal yang sama, di-*assign* sebuah value numeric {0,1,2,...}\n",
    "4. Didapatkanlah data set yang atributnya adalah nilai numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Skenario Eksperimen\n",
    "Pada eksperimen ini, skenario yang kami lakukan yaitu\n",
    "1. Membaca dataset\n",
    "2. Melakukan *preprocessing*\n",
    "3. Melakukan *fit* datates terhadap *classifier* (ANN dan DTL)\n",
    "4. Melakukan Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lalu, faktor yang memperngaruhi hasil testing terhadap hasil eksperimen, yaitu *classifier* yang digunakan. Setiap classifier, ada beberapa faktor yang mempengaruhi pula. yaitu:\n",
    "1. DTL: jumlah *node* daun maksimal \n",
    "2. ANN: jumlah *Hidden Layer* dan *Hidden State* pada setiap *layer*-nya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hasil Eksperimen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membaca Dataset CensusIncome (.csv Format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.get_dataset('CencusIncome.data.csv', 14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing yang Dilakukan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. (1) Training-Testing - DTL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Konfigurasi\n",
    "1. *node* maksimal pada daun = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.build_clf_full('dtl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. (2) Training-Testing - ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Konfigurasi\n",
    "1. *Hidden Layer* = 2\n",
    "2. *Hidden State* setiap *layer = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.build_clf_full('ann')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. (1) 10-fold Cross Validation - DTL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.852185464835\n"
     ]
    }
   ],
   "source": [
    "exp.get10FoldCrossValidation_dtl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. (2) 10-fold Cross Validation - ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.776142342066\n"
     ]
    }
   ],
   "source": [
    "exp.get10FoldCrossValidation_ann()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analisis Fitur (Menggunakan Seaborn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline \n",
    "\n",
    "# iris = sns.load_dataset('iris')\n",
    "# print(iris)\n",
    "# iris = exp.dataset\n",
    "# # print(iris)\n",
    "# sns.set(style=\"ticks\", color_codes=True) # change style\n",
    "# g = sns.pairplot(iris, hue=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penjelasan analisis fitur\n",
    "1. Data ini memiliki banyak fitur (totalnya 14 fitur)\n",
    "2. Setiap fitur memiliki persebaran klasifikasi yang berbeda-beda\n",
    "3. Dari pairplot, dapat dilihat bahwa setiap fitur memiliki kekuatan pengaruh yang berbeda-beda terhadap kelas\n",
    "4. Biarpun pengaruhnya berbeda-beda, tapi setiap fitur memiliki pengaruh terhadap klasifikasi\n",
    "4. Sehingga pada eksperimen kali ini, kami menggunakan seluruh fitur yang ada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Konsistensi Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Kesimpulan\n",
    "\n",
    "Pada Eksperimen ini, kesimpulan yang dapat diambil adalah:\n",
    "1. Beberapa data perlu dipreproses terlebih dahulu karena data di dunia nyata memiliki missing attribut, dan mungkin formatnya tidak sesuai\n",
    "2. DTL dengan max_leaf_node=20 menghasilkan akurasi 85,2%\n",
    "3. ANN dengan 1 hidden layer, 10 node hidden layer menghasilkan akurasi 77,6%\n",
    "4. DTL pada eksperimen kali ini lebih baik di bandingkan ANN\n",
    "5. Kekuatan setiap fitur untuk mengklasifikasikan data berbeda-beda, dilihat dari pair plot seaborn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
